{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dataset is split into train and test, with 11000 tweets in training set and the rest in test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df=pd.read_csv(\"final_dataset.csv\")\n",
    "# test_data = df[11000:].copy()\n",
    "# data = df[:11000].copy()\n",
    "# print(data)\n",
    "\n",
    "df=pd.read_csv(\"final_dataset.csv\", names=['Tweet Id', 'Tweets', 'User Id', 'Screen Name', 'Class'])\n",
    "test_data = df[11000:].copy()\n",
    "data = df[:11000].copy()\n",
    "# print(data)\n",
    "print(data[\"Tweets\"].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processing(raw_tweet):\n",
    "    letters_only=re.sub(\"[^a-zA-Z]\",\" \",raw_tweet)\n",
    "    words=letters_only.lower().split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    m_w=[w for w in words if not w in stops]\n",
    "    return (\" \".join(m_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tweets=data[\"Tweets\"].size\n",
    "clean_tweet=[]\n",
    "for i in range(0,num_tweets):\n",
    "    clean_tweet.append(tweet_processing(data[\"Tweets\"][i]))\n",
    "data[\"Tweets\"]=clean_tweet \n",
    "\n",
    "\n",
    "num_tweets_test=test_data[\"Tweets\"].size\n",
    "clean_tweet_test=[]\n",
    "for i in range(num_tweets,num_tweets+num_tweets_test):\n",
    "    clean_tweet_test.append(tweet_processing(test_data[\"Tweets\"][i]))\n",
    "test_data[\"Tweets\"]=clean_tweet_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model : SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_svm, Y_train, Y_test_svm = train_test_split(df.Tweets, df.Class, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,max_features = 5000)\n",
    "\n",
    "train_data_features=vectorizer.fit_transform(X_train)\n",
    "train_data_features=train_data_features.toarray()\n",
    "\n",
    "test_data_features=vectorizer.transform(X_test_svm)\n",
    "test_data_features=test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Testing\n",
      "Accuracy:  0.8574580759046778\n"
     ]
    }
   ],
   "source": [
    "#SVM with linear kernel\n",
    "clf=svm.SVC(kernel='linear',C=1.0)\n",
    "print (\"Training\")\n",
    "clf.fit(train_data_features,Y_train)\n",
    "\n",
    "print (\"Testing\")\n",
    "predicted=clf.predict(test_data_features)\n",
    "accuracy=np.mean(predicted==Y_test_svm)\n",
    "print (\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precision,recall,F1 score for svm model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8534028329692774, 0.8574580759046778, 0.8544796030819005, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "score_svm=precision_recall_fscore_support(Y_test_svm, predicted, average='weighted')\n",
    "print(score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__creating one hot vector for classes(labels).__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sexism']=0\n",
    "data['racism']=0\n",
    "data['none']=0\n",
    "\n",
    "data['sexism'] = np.where(data['Class'] == 'sexism', 1, 0)\n",
    "data['racism'] = np.where(data['Class'] == 'racism', 1, 0)\n",
    "data['none'] = np.where(data['Class'] == 'none', 1, 0)\n",
    "#data.head()\n",
    "columns=['sexism','racism','none']\n",
    "y=data[columns].values\n",
    "#print(y.shape)\n",
    "\n",
    "\n",
    "test_data['sexism']=0\n",
    "test_data['racism']=0\n",
    "test_data['none']=0\n",
    "\n",
    "test_data['sexism'] = np.where(test_data['Class'] == 'sexism', 1, 0)\n",
    "test_data['racism'] = np.where(test_data['Class'] == 'racism', 1, 0)\n",
    "test_data['none'] = np.where(test_data['Class'] == 'none', 1, 0)\n",
    "#data.head()\n",
    "columns=['sexism','racism','none']\n",
    "y_test=test_data[columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenizing words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#text1 = \"It's true that the chicken was the best bamboozler in the known multiverse.\"\n",
    "#tokens = word_tokenize(data['Tweets'])\n",
    "data['tokenized_sents'] = data.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n",
    "test_data['tokenized_sents'] = test_data.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n",
    "df['tokenized_sents'] = df.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating word embeddings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "vocab_size = 22194\n",
    "# define training data\n",
    "sentences = df['tokenized_sents']\n",
    "# train model\n",
    "model = Word2Vec(sentences,size=200,window =4,min_count=1,sg=1)\n",
    "#print(model)\n",
    "words = list(model.wv.vocab)\n",
    "#print(len(words))\n",
    "model.save('model.bin')\n",
    "\n",
    "#model = Word2Vec.load('model.bin')\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__creating embedding matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,200))\n",
    "\n",
    "for i in range(0,len(words)):\n",
    "    embedding_vector = model[words[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix[vocab_size-1]= np.random.normal(scale=0.6, size=(200, ))\n",
    "    \n",
    "#print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using Keras to train LSTM model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__resizing each tweet to size 50__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['tokenized_sents'])\n",
    "sequences = tokenizer.texts_to_sequences(data['tokenized_sents'])\n",
    "X_t = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "#print(vocab_size)\n",
    "tokenizer.fit_on_texts(test_data['tokenized_sents'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['tokenized_sents'])\n",
    "X_test = pad_sequences(test_sequences, maxlen=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__calculating a user's tendency towards racism, sexism, neutrality by taking the ratio of number of tweets marked as a particular label and total number of tweets of that user. This is done for each label(sexism, racism and neutral)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User Id' '949380854' '297877558' ... '29424561' '289846547' '29424561']\n"
     ]
    }
   ],
   "source": [
    "count1=[]\n",
    "print(data['User Id'].values)\n",
    "for i in data['User Id'].unique():\n",
    "    #print(i)\n",
    "    count1.append((data['User Id']== i).sum())\n",
    "#print(count1)\n",
    "neutral_count=[]\n",
    "sexism_count=[]\n",
    "racism_count=[]\n",
    "for i in data['User Id'].unique():\n",
    "    neutral_count.append(len(data[(data['User Id']==i) & (data['Class']=='none')]))\n",
    "    sexism_count.append(len(data[(data['User Id']==i) & (data['Class']=='sexism')]))\n",
    "    racism_count.append(len(data[(data['User Id']==i) & (data['Class']=='racism')])) \n",
    "    \n",
    "count_test=[]\n",
    "#print(data['User Id'].values)\n",
    "for i in test_data['User Id'].unique():\n",
    "    #print(i)\n",
    "    count_test.append((test_data['User Id']== i).sum())\n",
    "#print(count1)\n",
    "neutral_count_test=[]\n",
    "sexism_count_test=[]\n",
    "racism_count_test=[]\n",
    "for i in test_data['User Id'].unique():\n",
    "    #neutral_count.append((data['User Id']==i) & (data['Class']== 'none').sum())\n",
    "    neutral_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='none')]))\n",
    "    sexism_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='sexism')]))\n",
    "    racism_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='racism')])) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_len = len(data['User Id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_sexism=[]\n",
    "ratio_neutral=[]\n",
    "ratio_racism=[]\n",
    "\n",
    "for i in range(0,X_len):\n",
    "    ratio_sexism.append(sexism_count[i]/count1[i])\n",
    "    ratio_racism.append(racism_count[i]/count1[i])\n",
    "    ratio_neutral.append(neutral_count[i]/count1[i])\n",
    "        \n",
    "#make a column for ratio of eachc class\n",
    "\n",
    "ratio_sexism_test=[]\n",
    "ratio_neutral_test=[]\n",
    "ratio_racism_test=[]\n",
    "\n",
    "for i in range(0,len(test_data['User Id'].unique())):\n",
    "    ratio_sexism_test.append(sexism_count_test[i]/count_test[i])\n",
    "    ratio_racism_test.append(racism_count_test[i]/count_test[i])\n",
    "    ratio_neutral_test.append(neutral_count_test[i]/count_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in data['User Id'].unique():\n",
    "    \n",
    "    #print(i)\n",
    "    data.loc[data['User Id'] == i,'tendency_sexual'] = ratio_sexism[j]\n",
    "    data.loc[data['User Id'] == i,'tendency_racism'] = ratio_racism[j]\n",
    "    data.loc[data['User Id'] == i,'tendency_neutral'] = ratio_neutral[j]\n",
    "    j=j+1\n",
    "\n",
    "k=0\n",
    "for i in test_data['User Id'].unique():\n",
    "    \n",
    "    #print(i)\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_sexual'] = ratio_sexism_test[k]\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_racism'] = ratio_racism_test[k]\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_neutral'] = ratio_neutral_test[k]\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 1)\n"
     ]
    }
   ],
   "source": [
    "# tendency_sexism=data['tendency_sexual'].as_matrix()\n",
    "# tendency_racism=data['tendency_racism'].as_matrix()\n",
    "# tendency_neutral=data['tendency_neutral'].as_matrix()\n",
    "\n",
    "tendency_sexism=data['tendency_sexual'].to_numpy()\n",
    "tendency_racism=data['tendency_racism'].to_numpy()\n",
    "tendency_neutral=data['tendency_neutral'].to_numpy()\n",
    "\n",
    "\n",
    "tendency_sexism=tendency_sexism.reshape(len(tendency_sexism),1)\n",
    "tendency_racism=tendency_sexism.reshape(len(tendency_racism),1)\n",
    "tendency_neutral=tendency_sexism.reshape(len(tendency_neutral),1)\n",
    "print(tendency_sexism.shape)\n",
    "\n",
    "# tendency_sexism_test=test_data['tendency_sexual'].as_matrix()\n",
    "# tendency_racism_test=test_data['tendency_racism'].as_matrix()\n",
    "# tendency_neutral_test=test_data['tendency_neutral'].as_matrix()\n",
    "\n",
    "tendency_sexism_test=test_data['tendency_sexual'].to_numpy()\n",
    "tendency_racism_test=test_data['tendency_racism'].to_numpy()\n",
    "tendency_neutral_test=test_data['tendency_neutral'].to_numpy()\n",
    "\n",
    "\n",
    "tendency_sexism_test=tendency_sexism_test.reshape(len(tendency_sexism_test),1)\n",
    "tendency_racism_test=tendency_sexism_test.reshape(len(tendency_racism_test),1)\n",
    "tendency_neutral_test=tendency_sexism_test.reshape(len(tendency_neutral_test),1)\n",
    "#print(tendency_sexism.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__concatenating word vectors with tendencies of users calculated above for each label__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 53)\n"
     ]
    }
   ],
   "source": [
    "#print(X_t)\n",
    "X1_t=np.concatenate((X_t, tendency_sexism), axis=1)\n",
    "X1_t=np.concatenate((X1_t, tendency_racism), axis=1)\n",
    "X1_t=np.concatenate((X1_t, tendency_neutral), axis=1)\n",
    "print(X1_t.shape)\n",
    "\n",
    "\n",
    "X1_test=np.concatenate((X_test, tendency_sexism_test), axis=1)\n",
    "X1_test=np.concatenate((X1_test, tendency_racism_test), axis=1)\n",
    "X1_test=np.concatenate((X1_test, tendency_neutral_test), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training LSTM Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.4653 - accuracy: 0.7617 - val_loss: 0.3904 - val_accuracy: 0.8709\n",
      "Epoch 2/5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2972 - accuracy: 0.8872 - val_loss: 0.3267 - val_accuracy: 0.8827\n",
      "Epoch 3/5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.2178 - accuracy: 0.9236 - val_loss: 0.2641 - val_accuracy: 0.8891\n",
      "Epoch 4/5\n",
      "310/310 [==============================] - 17s 56ms/step - loss: 0.1496 - accuracy: 0.9527 - val_loss: 0.4046 - val_accuracy: 0.8818\n",
      "Epoch 5/5\n",
      "310/310 [==============================] - 16s 50ms/step - loss: 0.1360 - accuracy: 0.9636 - val_loss: 0.5306 - val_accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(53,))\n",
    "x = Embedding(vocab_size,200,weights=[embedding_matrix])(inp)\n",
    "#print(x.values)\n",
    "x = (LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.4))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50)(x)\n",
    "x=LeakyReLU(alpha=0.02)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(3)(x)\n",
    "x=LeakyReLU(alpha=0.02)(x)\n",
    "model1 = Model(inputs=inp, outputs=x)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X1_t,y, batch_size=32, epochs=5, validation_split=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "model1.save('model_lstm.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__training a bideirectional LSTM model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "310/310 [==============================] - 21s 68ms/step - loss: 0.4521 - accuracy: 0.7569 - val_loss: 0.2661 - val_accuracy: 0.8682\n",
      "Epoch 2/5\n",
      "310/310 [==============================] - 21s 68ms/step - loss: 0.3008 - accuracy: 0.8901 - val_loss: 0.2763 - val_accuracy: 0.8827\n",
      "Epoch 3/5\n",
      "310/310 [==============================] - 21s 69ms/step - loss: 0.2141 - accuracy: 0.9307 - val_loss: 0.3933 - val_accuracy: 0.8855\n",
      "Epoch 4/5\n",
      "310/310 [==============================] - 19s 62ms/step - loss: 0.1397 - accuracy: 0.9610 - val_loss: 0.4764 - val_accuracy: 0.8845\n",
      "Epoch 5/5\n",
      "310/310 [==============================] - 20s 63ms/step - loss: 0.1335 - accuracy: 0.9626 - val_loss: 0.4595 - val_accuracy: 0.8891\n"
     ]
    }
   ],
   "source": [
    "inp_bi = Input(shape=(53,))\n",
    "x_bi = Embedding(vocab_size,200,weights=[embedding_matrix])(inp_bi)\n",
    "#print(x.values)\n",
    "x_bi = Bidirectional(LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.4))(x_bi)\n",
    "x_bi = GlobalMaxPool1D()(x_bi)\n",
    "x_bi = Dense(50)(x_bi)\n",
    "x_bi=LeakyReLU(alpha=0.02)(x_bi)\n",
    "x_bi = Dropout(0.2)(x_bi)\n",
    "x_bi = Dense(3)(x_bi)\n",
    "x_bi=LeakyReLU(alpha=0.02)(x_bi)\n",
    "model_bi = Model(inputs=inp_bi, outputs=x_bi)\n",
    "model_bi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_bi.fit(X1_t,y, batch_size=32, epochs=5, validation_split=0.1);\n",
    "model_bi.save('model_bi.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating  precision,recall,F1score, of LSTM and bidirectional model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lstm = model1.predict(X1_test)\n",
    "predicted_bi = model_bi.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_lstm = pd.DataFrame.from_records(predicted_lstm)\n",
    "dataframe_bi=pd.DataFrame.from_records(predicted_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__predicted class is stored in a column of dataframe__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__bidirectional lstm results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get label function creates appropriate labels according to  predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(df):\n",
    "    if ((df[0] >df[1]) & (df[0] > df[2])):\n",
    "        return 'Sexism'\n",
    "    elif ((df[1] >df[0]) & (df[1] > df[2])):\n",
    "        return 'Racism'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "\n",
    "dataframe_lstm['predClass'] = dataframe_lstm.apply(lambda row: get_label(row), axis=1)\n",
    "dataframe_bi['predClass'] = dataframe_bi.apply(lambda row: get_label(row), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        none\n",
      "1        none\n",
      "2        none\n",
      "3        none\n",
      "4      Sexism\n",
      "        ...  \n",
      "321      none\n",
      "322      none\n",
      "323      none\n",
      "324    Sexism\n",
      "325    Sexism\n",
      "Name: predClass, Length: 326, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_bi['predClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        none\n",
      "1        none\n",
      "2        none\n",
      "3        none\n",
      "4      Sexism\n",
      "        ...  \n",
      "321      none\n",
      "322      none\n",
      "323      none\n",
      "324    Sexism\n",
      "325      none\n",
      "Name: predClass, Length: 326, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_lstm['predClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8813461367475771, 0.7975460122699386, 0.8373546772541526, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "score_lstm=precision_recall_fscore_support(test_data['Class'],dataframe_lstm['predClass'],average='weighted')\n",
    "print(score_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bidirectional LSTM score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 0.0, None)\n"
     ]
    }
   ],
   "source": [
    "score_bi=precision_recall_fscore_support(test_data['Class'],dataframe_bi['predClass'],average='weighted')\n",
    "print(score_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precision recall and f1 scores for svm and deep learning models__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_bi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-01740563c6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_svm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_svm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_svm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_bi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_bi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_bi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"F1-score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Bidirectional LSTM'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_bi' is not defined"
     ]
    }
   ],
   "source": [
    "summary = [[score_svm[0],score_svm[1],score_svm[2]], [score_lstm[0],score_lstm[1],score_lstm[2] ],[score_bi[0],score_bi[1],score_bi[2]]]\n",
    "score=pd.DataFrame(summary, columns=[\"Precision\", \"Recall\",\"F1-score\"])\n",
    "score.rename(index={0:'SVM',1:'LSTM',2:'Bidirectional LSTM'}, inplace=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
