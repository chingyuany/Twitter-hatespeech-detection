{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dataset is split into train and test, with 11000 tweets in training set and the rest in test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Tweet Id                                             Tweets  \\\n",
      "0     560299163200815104  .@aamattyhealy You won't answer, like most fem...   \n",
      "1     560313899099373568  @TheGags29  Nope.  Jessi and many other femini...   \n",
      "2     560181343926353920  RT @CHSommers: How NPR helped create the curre...   \n",
      "3     560191214344224768  RT @AlMartin2000: @Jackbarnesmra @AVoiceForMen...   \n",
      "4     560481970338430977  .@JenLawliet @SwitchManZZZ Actually, I explain...   \n",
      "...                  ...                                                ...   \n",
      "5268  563201540647686144  My stepdad walked into the room to offer me po...   \n",
      "5269  563035498986631169  @a_man_in_black noted. Although this is tricky...   \n",
      "5270  563029199011983361     @desertfox899 is this 1997??? who uses MSN????   \n",
      "5271  563038441479634948  OHMYGOD I just realized what \"my soggy knees\" ...   \n",
      "5272  563029922311311360  @8BitBecca things need to start small and then...   \n",
      "\n",
      "         User Id     Screen Name   Class  \n",
      "0     2756873076           MT8_9  sexism  \n",
      "1     2756873076           MT8_9  sexism  \n",
      "2     2756873076           MT8_9  sexism  \n",
      "3     2756873076           MT8_9  sexism  \n",
      "4     2756873076           MT8_9  sexism  \n",
      "...          ...             ...     ...  \n",
      "5268    13857342  randileeharper    none  \n",
      "5269    13857342  randileeharper    none  \n",
      "5270    13857342  randileeharper    none  \n",
      "5271    13857342  randileeharper    none  \n",
      "5272    13857342  randileeharper    none  \n",
      "\n",
      "[5273 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df=pd.read_csv(\"final_dataset.csv\")\n",
    "# test_data = df[11000:].copy()\n",
    "# data = df[:11000].copy()\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "df=pd.read_csv(\"reconstruct_paper_dataset1.csv\", names=['Tweet Id', 'Tweets', 'User Id', 'Screen Name', 'Class'])\n",
    "# df1=pd.read_csv(\"reconstruct_paper_dataset1.csv\")\n",
    "# print(df)\n",
    "test_data1 = df1[1:].copy()\n",
    "data1 = df1[:1].copy()\n",
    "\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_processing(raw_tweet):\n",
    "    letters_only=re.sub(\"[^a-zA-Z]\",\" \",raw_tweet)\n",
    "    words=letters_only.lower().split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    m_w=[w for w in words if not w in stops]\n",
    "    return (\" \".join(m_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tweets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-18a852464388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_tweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tweets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclean_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tweets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tweets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tweets'"
     ]
    }
   ],
   "source": [
    "num_tweets=data[\"Tweets\"].size\n",
    "clean_tweet=[]\n",
    "for i in range(0,num_tweets):\n",
    "    clean_tweet.append(tweet_processing(data[\"Tweets\"][i]))\n",
    "data[\"Tweets\"]=clean_tweet \n",
    "\n",
    "\n",
    "num_tweets_test=test_data[\"Tweets\"].size\n",
    "clean_tweet_test=[]\n",
    "for i in range(num_tweets,num_tweets+num_tweets_test):\n",
    "    clean_tweet_test.append(tweet_processing(test_data[\"Tweets\"][i]))\n",
    "test_data[\"Tweets\"]=clean_tweet_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model : SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_svm, Y_train, Y_test_svm = train_test_split(df.Tweets, df.Class, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,max_features = 5000)\n",
    "\n",
    "train_data_features=vectorizer.fit_transform(X_train)\n",
    "train_data_features=train_data_features.toarray()\n",
    "\n",
    "test_data_features=vectorizer.transform(X_test_svm)\n",
    "test_data_features=test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Testing\n",
      "Accuracy:  0.8520971302428256\n"
     ]
    }
   ],
   "source": [
    "#SVM with linear kernel\n",
    "clf=svm.SVC(kernel='linear',C=1.0)\n",
    "print (\"Training\")\n",
    "clf.fit(train_data_features,Y_train)\n",
    "\n",
    "print (\"Testing\")\n",
    "predicted=clf.predict(test_data_features)\n",
    "accuracy=np.mean(predicted==Y_test_svm)\n",
    "print (\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precision,recall,F1 score for svm model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8462801321834283, 0.8520971302428256, 0.8475775160464674, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "score_svm=precision_recall_fscore_support(Y_test_svm, predicted, average='weighted')\n",
    "print(score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__creating one hot vector for classes(labels).__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sexism']=0\n",
    "data['racism']=0\n",
    "data['none']=0\n",
    "\n",
    "data['sexism'] = np.where(data['Class'] == 'sexism', 1, 0)\n",
    "data['racism'] = np.where(data['Class'] == 'racism', 1, 0)\n",
    "data['none'] = np.where(data['Class'] == 'none', 1, 0)\n",
    "#data.head()\n",
    "columns=['sexism','racism','none']\n",
    "y=data[columns].values\n",
    "#print(y.shape)\n",
    "\n",
    "\n",
    "test_data['sexism']=0\n",
    "test_data['racism']=0\n",
    "test_data['none']=0\n",
    "\n",
    "test_data['sexism'] = np.where(test_data['Class'] == 'sexism', 1, 0)\n",
    "test_data['racism'] = np.where(test_data['Class'] == 'racism', 1, 0)\n",
    "test_data['none'] = np.where(test_data['Class'] == 'none', 1, 0)\n",
    "#data.head()\n",
    "columns=['sexism','racism','none']\n",
    "y_test=test_data[columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenizing words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#text1 = \"It's true that the chicken was the best bamboozler in the known multiverse.\"\n",
    "#tokens = word_tokenize(data['Tweets'])\n",
    "data['tokenized_sents'] = data.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n",
    "test_data['tokenized_sents'] = test_data.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n",
    "df['tokenized_sents'] = df.apply(lambda column: word_tokenize(column['Tweets']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating word embeddings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "vocab_size = 22194\n",
    "# define training data\n",
    "sentences = df['tokenized_sents']\n",
    "# train model\n",
    "model = Word2Vec(sentences,size=200,window =4,min_count=1,sg=1)\n",
    "#print(model)\n",
    "words = list(model.wv.vocab)\n",
    "#print(len(words))\n",
    "model.save('model.bin')\n",
    "\n",
    "#model = Word2Vec.load('model.bin')\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__creating embedding matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,200))\n",
    "\n",
    "for i in range(0,len(words)):\n",
    "    embedding_vector = model[words[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix[vocab_size-1]= np.random.normal(scale=0.6, size=(200, ))\n",
    "    \n",
    "#print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using Keras to train LSTM model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__resizing each tweet to size 50__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['tokenized_sents'])\n",
    "sequences = tokenizer.texts_to_sequences(data['tokenized_sents'])\n",
    "X_t = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "#print(vocab_size)\n",
    "tokenizer.fit_on_texts(test_data['tokenized_sents'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['tokenized_sents'])\n",
    "X_test = pad_sequences(test_sequences, maxlen=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__calculating a user's tendency towards racism, sexism, neutrality by taking the ratio of number of tweets marked as a particular label and total number of tweets of that user. This is done for each label(sexism, racism and neutral)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[949380854 297877558 272704749 ... 289846547  29424561 289846547]\n"
     ]
    }
   ],
   "source": [
    "count1=[]\n",
    "print(data['User Id'].values)\n",
    "for i in data['User Id'].unique():\n",
    "    #print(i)\n",
    "    count1.append((data['User Id']== i).sum())\n",
    "#print(count1)\n",
    "neutral_count=[]\n",
    "sexism_count=[]\n",
    "racism_count=[]\n",
    "for i in data['User Id'].unique():\n",
    "    neutral_count.append(len(data[(data['User Id']==i) & (data['Class']=='none')]))\n",
    "    sexism_count.append(len(data[(data['User Id']==i) & (data['Class']=='sexism')]))\n",
    "    racism_count.append(len(data[(data['User Id']==i) & (data['Class']=='racism')])) \n",
    "    \n",
    "count_test=[]\n",
    "#print(data['User Id'].values)\n",
    "for i in test_data['User Id'].unique():\n",
    "    #print(i)\n",
    "    count_test.append((test_data['User Id']== i).sum())\n",
    "#print(count1)\n",
    "neutral_count_test=[]\n",
    "sexism_count_test=[]\n",
    "racism_count_test=[]\n",
    "for i in test_data['User Id'].unique():\n",
    "    #neutral_count.append((data['User Id']==i) & (data['Class']== 'none').sum())\n",
    "    neutral_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='none')]))\n",
    "    sexism_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='sexism')]))\n",
    "    racism_count_test.append(len(test_data[(test_data['User Id']==i) & (test_data['Class']=='racism')])) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_len = len(data['User Id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_sexism=[]\n",
    "ratio_neutral=[]\n",
    "ratio_racism=[]\n",
    "\n",
    "for i in range(0,X_len):\n",
    "    ratio_sexism.append(sexism_count[i]/count1[i])\n",
    "    ratio_racism.append(racism_count[i]/count1[i])\n",
    "    ratio_neutral.append(neutral_count[i]/count1[i])\n",
    "        \n",
    "#make a column for ratio of eachc class\n",
    "\n",
    "ratio_sexism_test=[]\n",
    "ratio_neutral_test=[]\n",
    "ratio_racism_test=[]\n",
    "\n",
    "for i in range(0,len(test_data['User Id'].unique())):\n",
    "    ratio_sexism_test.append(sexism_count_test[i]/count_test[i])\n",
    "    ratio_racism_test.append(racism_count_test[i]/count_test[i])\n",
    "    ratio_neutral_test.append(neutral_count_test[i]/count_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in data['User Id'].unique():\n",
    "    \n",
    "    #print(i)\n",
    "    data.loc[data['User Id'] == i,'tendency_sexual'] = ratio_sexism[j]\n",
    "    data.loc[data['User Id'] == i,'tendency_racism'] = ratio_racism[j]\n",
    "    data.loc[data['User Id'] == i,'tendency_neutral'] = ratio_neutral[j]\n",
    "    j=j+1\n",
    "\n",
    "k=0\n",
    "for i in test_data['User Id'].unique():\n",
    "    \n",
    "    #print(i)\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_sexual'] = ratio_sexism_test[k]\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_racism'] = ratio_racism_test[k]\n",
    "    test_data.loc[test_data['User Id'] == i,'tendency_neutral'] = ratio_neutral_test[k]\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 1)\n"
     ]
    }
   ],
   "source": [
    "# tendency_sexism=data['tendency_sexual'].as_matrix()\n",
    "# tendency_racism=data['tendency_racism'].as_matrix()\n",
    "# tendency_neutral=data['tendency_neutral'].as_matrix()\n",
    "\n",
    "tendency_sexism=data['tendency_sexual'].to_numpy()\n",
    "tendency_racism=data['tendency_racism'].to_numpy()\n",
    "tendency_neutral=data['tendency_neutral'].to_numpy()\n",
    "\n",
    "\n",
    "tendency_sexism=tendency_sexism.reshape(len(tendency_sexism),1)\n",
    "tendency_racism=tendency_sexism.reshape(len(tendency_racism),1)\n",
    "tendency_neutral=tendency_sexism.reshape(len(tendency_neutral),1)\n",
    "print(tendency_sexism.shape)\n",
    "\n",
    "# tendency_sexism_test=test_data['tendency_sexual'].as_matrix()\n",
    "# tendency_racism_test=test_data['tendency_racism'].as_matrix()\n",
    "# tendency_neutral_test=test_data['tendency_neutral'].as_matrix()\n",
    "\n",
    "tendency_sexism_test=test_data['tendency_sexual'].to_numpy()\n",
    "tendency_racism_test=test_data['tendency_racism'].to_numpy()\n",
    "tendency_neutral_test=test_data['tendency_neutral'].to_numpy()\n",
    "\n",
    "\n",
    "tendency_sexism_test=tendency_sexism_test.reshape(len(tendency_sexism_test),1)\n",
    "tendency_racism_test=tendency_sexism_test.reshape(len(tendency_racism_test),1)\n",
    "tendency_neutral_test=tendency_sexism_test.reshape(len(tendency_neutral_test),1)\n",
    "#print(tendency_sexism.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__concatenating word vectors with tendencies of users calculated above for each label__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 53)\n"
     ]
    }
   ],
   "source": [
    "#print(X_t)\n",
    "X1_t=np.concatenate((X_t, tendency_sexism), axis=1)\n",
    "X1_t=np.concatenate((X1_t, tendency_racism), axis=1)\n",
    "X1_t=np.concatenate((X1_t, tendency_neutral), axis=1)\n",
    "print(X1_t.shape)\n",
    "\n",
    "\n",
    "X1_test=np.concatenate((X_test, tendency_sexism_test), axis=1)\n",
    "X1_test=np.concatenate((X1_test, tendency_racism_test), axis=1)\n",
    "X1_test=np.concatenate((X1_test, tendency_neutral_test), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training LSTM Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "310/310 [==============================] - 23s 75ms/step - loss: 0.6698 - accuracy: 0.7045 - val_loss: 0.2899 - val_accuracy: 0.8564\n",
      "Epoch 2/5\n",
      "310/310 [==============================] - 23s 73ms/step - loss: 0.3051 - accuracy: 0.8647 - val_loss: 0.2895 - val_accuracy: 0.8627\n",
      "Epoch 3/5\n",
      "310/310 [==============================] - 23s 74ms/step - loss: 0.1807 - accuracy: 0.9348 - val_loss: 0.4017 - val_accuracy: 0.8209\n",
      "Epoch 4/5\n",
      "310/310 [==============================] - 23s 74ms/step - loss: 3.7001 - accuracy: 0.3013 - val_loss: 4.4182 - val_accuracy: 0.1645\n",
      "Epoch 5/5\n",
      "310/310 [==============================] - 23s 75ms/step - loss: 1.2742 - accuracy: 0.7689 - val_loss: 0.5279 - val_accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(53,))\n",
    "x = Embedding(vocab_size,200,weights=[embedding_matrix])(inp)\n",
    "#print(x.values)\n",
    "x = (LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.4))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50)(x)\n",
    "x=LeakyReLU(alpha=0.02)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(3)(x)\n",
    "x=LeakyReLU(alpha=0.02)(x)\n",
    "model1 = Model(inputs=inp, outputs=x)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X1_t,y, batch_size=32, epochs=5, validation_split=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "model1.save('model_lstm.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__training a bideirectional LSTM model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "310/310 [==============================] - 27s 87ms/step - loss: 0.7532 - accuracy: 0.6975 - val_loss: 0.3300 - val_accuracy: 0.8818\n",
      "Epoch 2/5\n",
      "310/310 [==============================] - 26s 85ms/step - loss: 0.3024 - accuracy: 0.8752 - val_loss: 0.2174 - val_accuracy: 0.8936\n",
      "Epoch 3/5\n",
      "310/310 [==============================] - 28s 90ms/step - loss: 0.2193 - accuracy: 0.9224 - val_loss: 0.3356 - val_accuracy: 0.8900\n",
      "Epoch 4/5\n",
      "310/310 [==============================] - 29s 93ms/step - loss: 0.1771 - accuracy: 0.9481 - val_loss: 0.6275 - val_accuracy: 0.8518\n",
      "Epoch 5/5\n",
      "310/310 [==============================] - 29s 94ms/step - loss: 0.1162 - accuracy: 0.9649 - val_loss: 0.4950 - val_accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "inp_bi = Input(shape=(53,))\n",
    "x_bi = Embedding(vocab_size,200,weights=[embedding_matrix])(inp_bi)\n",
    "#print(x.values)\n",
    "x_bi = Bidirectional(LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.4))(x_bi)\n",
    "x_bi = GlobalMaxPool1D()(x_bi)\n",
    "x_bi = Dense(50)(x_bi)\n",
    "x_bi=LeakyReLU(alpha=0.02)(x_bi)\n",
    "x_bi = Dropout(0.2)(x_bi)\n",
    "x_bi = Dense(3)(x_bi)\n",
    "x_bi=LeakyReLU(alpha=0.02)(x_bi)\n",
    "model_bi = Model(inputs=inp_bi, outputs=x_bi)\n",
    "model_bi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_bi.fit(X1_t,y, batch_size=32, epochs=5, validation_split=0.1);\n",
    "model_bi.save('model_bi.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating  precision,recall,F1score, of LSTM and bidirectional model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lstm = model1.predict(X1_test)\n",
    "predicted_bi = model_bi.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_lstm = pd.DataFrame.from_records(predicted_lstm)\n",
    "dataframe_bi=pd.DataFrame.from_records(predicted_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__predicted class is stored in a column of dataframe__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__bidirectional lstm results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get label function creates appropriate labels according to  predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(df):\n",
    "    if ((df[0] >df[1]) & (df[0] > df[2])):\n",
    "        return 'Sexism'\n",
    "    elif ((df[1] >df[0]) & (df[1] > df[2])):\n",
    "        return 'Racism'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "\n",
    "dataframe_lstm['predClass'] = dataframe_lstm.apply(lambda row: get_label(row), axis=1)\n",
    "dataframe_bi['predClass'] = dataframe_bi.apply(lambda row: get_label(row), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        none\n",
      "1        none\n",
      "2        none\n",
      "3        none\n",
      "4      Sexism\n",
      "5      Sexism\n",
      "6        none\n",
      "7        none\n",
      "8        none\n",
      "9      Sexism\n",
      "10       none\n",
      "11     Sexism\n",
      "12       none\n",
      "13       none\n",
      "14       none\n",
      "15       none\n",
      "16       none\n",
      "17       none\n",
      "18       none\n",
      "19       none\n",
      "20       none\n",
      "21       none\n",
      "22       none\n",
      "23       none\n",
      "24       none\n",
      "25       none\n",
      "26       none\n",
      "27       none\n",
      "28     Sexism\n",
      "29       none\n",
      "        ...  \n",
      "295      none\n",
      "296    Sexism\n",
      "297    Sexism\n",
      "298      none\n",
      "299    Sexism\n",
      "300    Sexism\n",
      "301      none\n",
      "302      none\n",
      "303      none\n",
      "304      none\n",
      "305      none\n",
      "306      none\n",
      "307      none\n",
      "308      none\n",
      "309    Sexism\n",
      "310      none\n",
      "311      none\n",
      "312    Sexism\n",
      "313    Sexism\n",
      "314      none\n",
      "315    Sexism\n",
      "316      none\n",
      "317      none\n",
      "318      none\n",
      "319      none\n",
      "320      none\n",
      "321      none\n",
      "322      none\n",
      "323    Sexism\n",
      "324    Sexism\n",
      "Name: predClass, Length: 325, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_bi['predClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        none\n",
      "1        none\n",
      "2        none\n",
      "3        none\n",
      "4        none\n",
      "        ...  \n",
      "320      none\n",
      "321      none\n",
      "322    Sexism\n",
      "323    Sexism\n",
      "324    Sexism\n",
      "Name: predClass, Length: 325, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_lstm['predClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8914698447092813, 0.6246153846153846, 0.734557357536081, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/qiqingh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "score_lstm=precision_recall_fscore_support(test_data['Class'],dataframe_lstm['predClass'],average='weighted')\n",
    "print(score_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bidirectional LSTM score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8801589554357082, 0.7846153846153846, 0.8296454849498328, None)\n"
     ]
    }
   ],
   "source": [
    "score_bi=precision_recall_fscore_support(test_data['Class'],dataframe_bi['predClass'],average='weighted')\n",
    "print(score_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precision recall and f1 scores for svm and deep learning models__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Precision    Recall  F1-score\n",
      "SVM                  0.846280  0.852097  0.847578\n",
      "LSTM                 0.891470  0.624615  0.734557\n",
      "Bidirectional LSTM   0.880159  0.784615  0.829645\n"
     ]
    }
   ],
   "source": [
    "summary = [[score_svm[0],score_svm[1],score_svm[2]], [score_lstm[0],score_lstm[1],score_lstm[2] ],[score_bi[0],score_bi[1],score_bi[2]]]\n",
    "score=pd.DataFrame(summary, columns=[\"Precision\", \"Recall\",\"F1-score\"])\n",
    "score.rename(index={0:'SVM',1:'LSTM',2:'Bidirectional LSTM'}, inplace=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
